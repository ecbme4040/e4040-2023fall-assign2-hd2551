{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columbia University\n",
    "### ECBM E4040 Neural Networks and Deep Learning. Fall 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECBM E4040 - Assignment 2 - Task 4: Data Augmentation & Transfer Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important factors in neural network training include the size and quality of the training set. Since it is often not possible to get a clean and large enough dataset for training, one way to improve the network's robustness and generalization ability is to create '*fake*' data by injecting random noise or to perform transformations on the available data. A technique which implements this strategy is called __data augmentation__ and has shown to be very effective.\n",
    "\n",
    "One thing to remember when you augment your data is to never change the correct label of a sample. For example, for hand-written digit dataset, rotating a letter '6' ends up looking like a letter '9', but you must keep the label for '6'. So rotation might not be the ideal augmentation technique for this task. It is important to choose wisely the best augmentation methods for your dataset.\n",
    "\n",
    "In the last part of this task, we introduce __transfer learning__ in TensorFlow to you by showing a demo. Test time augmentation (TTA) as additional content in data augmentation is also introduced based on your experiences on previous parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import modules\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ModuleNotFoundError:\n",
    "    os.system('pip install pandas')\n",
    "    import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "For this assignment, you will work with the Fashion-MNIST dataset provided by Zalando. This dataset serves as a drop-in replacement for the original MNIST dataset, offering a more challenging alternative for benchmarking machine learning algorithms.\n",
    "\n",
    "The dataset comprises 60,000 training examples and 10,000 testing examples. Each example in the dataset is a 28x28 grayscale image, associated with a label from one of the 10 classes, each representing a different article of clothing. The 10 classes are as follows:\n",
    "\n",
    "- 0 T-shirt/top\n",
    "- 1 Trouser\n",
    "- 2 Pullover\n",
    "- 3 Dress\n",
    "- 4 Coat\n",
    "- 5 Sandal\n",
    "- 6 Shirt\n",
    "- 7 Sneaker\n",
    "- 8 Bag\n",
    "- 9 Ankle boot\n",
    "\n",
    "![image](https://www.researchgate.net/publication/346405197/figure/fig3/AS:962581560848384@1606508736352/Examples-of-Fashion-MNIST-dataset.ppm)\n",
    "\n",
    "### Dataset Details:\n",
    "- Each image is 28 pixels in height and 28 pixels in width, resulting in a total of 784 pixels.\n",
    "- Each pixel holds an integer value between 0 and 255, representing the pixel's lightness or darkness, with higher numbers indicating darker pixels.\n",
    "- The dataset is split into training and test sets, with 785 columns in each set. The first column contains class labels representing the article of clothing, while the remaining 784 columns hold the pixel values of the associated image.\n",
    "### Understanding the Data:\n",
    "To locate a pixel in the image, suppose you have decomposed x into x = i * 28 + j, where i and j are integers ranging from 0 to 27. The pixel can then be located on row i and column j of a 28x28 matrix. For instance, pixel31 refers to the pixel situated in the fourth column from the left and the second row from the top.\n",
    "\n",
    "### Data Source and Acknowledgements:\n",
    "- The original Fashion-MNIST dataset can be downloaded from [Zalando's GitHub repository](https://github.com/zalandoresearch/fashion-mnist).\n",
    "- The dataset was converted to CSV format using a [script provided by pjreddie](https://pjreddie.com/projects/mnist-in-csv/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion MNIST data.\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "\n",
    "# Data organizations:\n",
    "# Train data: 50000 samples from original train set: 1~60000\n",
    "# Validation data: 10000 samples from original train set: 50001~60000\n",
    "# Test data: 10000 samples\n",
    "\n",
    "num_train = 50000\n",
    "num_valid = 10000\n",
    "num_test = 10000\n",
    "num_dev = 256\n",
    "\n",
    "X_train = X_train.reshape(num_train+num_valid, -1)\n",
    "X_test = X_test.reshape(num_valid,-1)\n",
    "\n",
    "# The development set is used for augmentation practices.\n",
    "mask = np.random.choice(num_train, num_dev, replace=False)\n",
    "X_dev = X_train[mask]\n",
    "y_dev = y_train[mask]\n",
    "\n",
    "# Seperate Training set into a training set and a validation set\n",
    "X_val = X_train[num_train:]\n",
    "y_val = y_train[num_train:]\n",
    "X_train = X_train[:num_train]\n",
    "y_train = y_train[:num_train]\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape)\n",
    "\n",
    "print(\"Number of classes: {}\".format(len(set(y_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some original images\n",
    "\n",
    "Here we use Pyplot to draw any 16 samples from the __development set__ in a 4-by-4 grid.\n",
    "\n",
    "__Note__: Since we have vectorized our data, we need to reshape it into 28 x 28 greyscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the original data.\n",
    "\n",
    "def plot(X, y, names, shape):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    for i in range(16):\n",
    "        ax = fig.add_subplot(4, 4, i+1)\n",
    "        ax.imshow(X[i, :].reshape(shape), 'gray')\n",
    "        ax.set_title(names[int(y[i])])\n",
    "        ax.axis('off')\n",
    "\n",
    "names = [\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]\n",
    "plot(X_dev, y_dev, names, (28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Automatic Batch Generator (5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want you to create an automatic image generator that does several kinds of data augmentations, and produces a batch of data consisting of random samples every time you call it. \n",
    "\n",
    "<span style=\"color:red\">__TODO__:</span> Finish the functions of class __ImageGenerator__ in **utils/image_generator.py**. The code is fully commented with instructions.\n",
    "\n",
    "__Hint__: The python keywords __yield__ and __next__ can help you do some tricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.image_generator import ImageGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an ImageGenerator object using the __development set__, and use __show__ function to plot the top 16 original images.\n",
    "\n",
    "__Note__: We need to reshape your data as the demanding input format of the class __ImageGenerator__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_dev.shape)\n",
    "print(X_dev.reshape(-1,1,28,28).transpose(0,2,3,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageGenerator(X_dev.reshape(-1,1,28,28).transpose(0,2,3,1), y_dev)\n",
    "gen.show(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Noise (Demo)\n",
    "\n",
    "Inject random noise into the original __development set__, and plot 16 images with noise added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added = gen.add_noise(1, 5)\n",
    "gen.show(added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate (Demo)\n",
    "\n",
    "Rotate the original __development set__ by several degrees and plot the top 16 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = gen.rotate(-90)\n",
    "gen.show(rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation\n",
    "\n",
    "<span style=\"color:red\">__TODO:__</span> Implement the function **translate()** in **utils/image_generator.py**. Shift the original __development set__ by several pixels in both directions, and plot the top 16 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal and Vertical Flip\n",
    "<span style=\"color:red\">__TODO:__</span> Implement the function **flip()** in **utils/image_generator.py**. Flip the original __development set__ as you like (horizontal, vertical, or both), and plot the top 16 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase Brightness\n",
    "\n",
    "<span style=\"color:red\">__TODO:__</span> Implement the function **brightness()** in **utils/image_generator.py**. Increase the brightness of the original __development set__, and plot 16 images with noise added. (These images may not be the same as the above 16 images according to your choice of parameters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Augmentation + LeNet (5%)\n",
    "\n",
    "<span style=\"color:red\">__TODO__:</span> Now you have your own data generator. You have been provided a simplified LeNet model in __utils/neuralnets/cnn/model_LeNet.py__. In __utils/neuralnets/cnn/my_LeNet_trainer.py__ you will find two TODOs. \n",
    "\n",
    "The first TODO asks you to **prepare batches of augmented training data** using the ImageGenerator you completed in the previous section. When generating augmented data, it is important to think carefully about the changes you are making to the data and the effect those changes may have on their classification. \n",
    "\n",
    "For example, look at these two images of a pullover and a shirt:\n",
    "\n",
    "<img src=\"data:image/png;base64,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\" />\n",
    "\n",
    "<img src=\"data:image/png;base64,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\" />\n",
    "\n",
    "When we increase it's birghtness by a factor of 10, we are unable to differentiate between the two. This might cause issues for the classifier in context of pullovers and shirts.  \n",
    "\n",
    "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACwCAYAAACW0FUFAAAABHNCSVQICAgIfAhkiAAAABl0RVh0U29mdHdhcmUAZ25vbWUtc2NyZWVuc2hvdO8Dvz4AAAAtdEVYdENyZWF0aW9uIFRpbWUATW9uIDA5IE9jdCAyMDIzIDEwOjAwOjM4IFBNIEVEVPS69BIAAANPSURBVHic7d09UuNIAIBRa4uI2DEknICTcAhfgoSAhEtwJk5ARExM6klmNtiSaodd6+fTvBdRXZQlrK+67KZlD+fz+XyAmL/WPgH4L4RL0tWvH4ZhWPM8sk6n0+j46+vrRR7/+vp6dPzr6+sij7+140755ytaMy5JwiVJuCQJl6Th1zru3G/OtvZif8pay9rfff7v7+9Hx9/e3i5xOpvjzRm7IFyShEuScEkSLkmLrSpsTX1T3NT1urm5GR3/+PiY83RmZ1WBXRAuScIlSbgkCZekq3//lXVM7W04Ho+j41PvmiurB4+Pj6PjLy8vo+NTf9fUasPU8/b5+fkbZ7c9ZlyShEuScEkSLknCJWn3exUqqwqX8qdcRzMuScIlSbgkCZck4ZK0+l6F7+7Y/9NWCb7ru8/P1CrE1j8Hw4xLknBJEi5JwiVJuCQttlfhUjvwrSpc1u3t7ej41KrOWndS2KvALgiXJOGSJFyShEvSZr8DwurBura2h8GqArsgXJKES5JwSRIuSavfAUGLOyDgfxAuScIlSbgkCZekzX5ao70K69p6D2ZckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJcgcEo56fn0fHn56eFj6TcWZckoRLknBJEi5JwiVp9Tsg3OnQspVOzLgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuSVdLHeh0Oi11KGb0/v4+On53d7foeZhxSRIuScIlSbgkCZek4Xw+nw+Hw2EYhlkP9PMw7NTS/ZhxSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSVrscxXmNrUD350X+2TGJUm4JAmXJOGSJFyScqsKU6sHDw8PC59Jy95WXcy4JAmXJOGSJFyShEvSYqsKc3+a3/F4nPXx92ru6zIXMy5JwiVJuCQJlyThkrTYd0Cspfq/+EurX1/fAcEuCJck4ZIkXJKES9LfqwpQYsYlSbgkCZck4ZIkXJJ+AFdWs3kBE8ZDAAAAAElFTkSuQmCC\" />\n",
    "\n",
    "<img src= \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACwCAYAAACW0FUFAAAABHNCSVQICAgIfAhkiAAAABl0RVh0U29mdHdhcmUAZ25vbWUtc2NyZWVuc2hvdO8Dvz4AAAAtdEVYdENyZWF0aW9uIFRpbWUATW9uIDA5IE9jdCAyMDIzIDEwOjAxOjI0IFBNIEVEVHXgKt4AAANJSURBVHic7d0xTuNAAEDRzYqKhhtASwq4BhUHgJprUHEHGqjhANwECmpuAA1ttkGrrOTVipWd+MN7XUZoYslfI3ls4sVqtVr9gJif2z4A+B/CJUm4JAmXpJ31D4vFYlvH8Sm7u7uD4+/v76PMP7fr1cp5mdr6ebHikiRckoRLknBJWqzfOfuqFwFnZ2eD43d3dxs+kv9zcnIyOL6/vz84fnt7O8r3Tn0R/FkuzsgTLknCJUm4JAmXpOSuwtxuydZ99rxva7fBrgJ5wiVJuCQJlyThkjSLXYWLi4vB8Zubmw0fCevmtttgV4E84ZIkXJKES5JwSZrFroJnD1rm0IkVlyThkiRckoRLknBJ2vn3n4zH7sHX8PDwMDh+enq6sWOw4pIkXJKES5JwSRIuSRt9VsGuwte2yX6suCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCTtTDHp9fX1FNPCb1ZckoRLknBJEi5JwiVpsVqtVr8/LBajTPr6+jo4vre3N8r8zNP5+fng+P39/Sjzr6VqxaVJuCQJlyThkiRckiZ5VsHuwfe0XC439l1WXJKES5JwSRIuScIlaZJnFdbvKcMUXVlxSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZekSd4BwTy9vb0Njhff2WHFJUm4JAmXJOGSJFySZv0OiKurq8Hxy8vLUeb/bv52fqd+Z4d3QMAH4ZIkXJKES5JwSZr1rsLBwcHg+MvLyyjzfzfL5XJw/Pn5edLvtasAH4RLknBJEi5JwiVp1rsK27q3zrjsKsAH4ZIkXJKES5JwSfK7Ct+I31WALRMuScIlSbgkCZek5K7C3+59Hx4eDo5P/YT/3Dw9PQ2OHx8fD44Xn/2w4pIkXJKES5JwSRIuScn/gGBcj4+Pg+NHR0ejzO8/IOCDcEkSLknCJUm4JP2xqwAVVlyShEuScEn6BVM5uJXTci4PAAAAAElFTkSuQmCC\" />\n",
    "\n",
    "<span style=\"color:red\">__TODO__:</span> Before completing the TODOs in __utils/neuralnets/cnn/my_LeNet_trainer.py__, explain which augmentations, or combination of augmentations (brightness, horizontal flip, vertical flip, translation, rotation, noise, etc.) could create similar issues for the classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__Your answer here__:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO__:</span> Propose a series of augmentations (at least 4) from the functions we implemented to generate an augmented training set. Be sure to avoid the issues discussed above and include argument parameters for the augmentation functions.\n",
    "\n",
    "Ex:\n",
    "\n",
    "1. flip('v')\n",
    "2. brightness(1.5)\n",
    "3. etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__Your answer here__:</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO__:</span> Complete the function **batch_train_data()** in **utils/neuralnets/cnn/my_LeNet_trainer.py** with your proposed data augmentations.\n",
    "\n",
    "<span style=\"color:red\">__TODO__:</span> Complete the function **train_epoch()** in **utils/neuralnets/cnn/my_LeNet_trainer.py**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Install tqdm__: tqdm is a fast, extensible progress meter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = X_train.reshape(-1,1,28,28).transpose(0,2,3,1)\n",
    "X_v = X_val.reshape(-1,1,28,28).transpose(0,2,3,1)\n",
    "\n",
    "print(X_t.shape)\n",
    "print(X_v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the LeNet Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.neuralnets.cnn.my_LeNet_trainer import MyLeNet_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO__:</span> train network using run method in MyLeNet_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 (Demos): Transfer Learning and Test Time Augmentation (TTA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the last part of assignment 2 before we go to the Kaggle competition. In this part, we will provide you with examples of transfer learning, as well as the last context of data augmentation: test time augmentation. We believe they are useful tools for task 5.\n",
    "\n",
    "__Note__: The network in demos is not guaranteed to be well-trained. __No points are set in this part__. Feel free to edit the scripts and tune the parameters by yourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "\n",
    "The intuition behind transfer learning is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model of the visual world. For a somewhat different problem, you can then take advantage of these learned feature maps without having to start from scratch and training a new large model on a large dataset.\n",
    "\n",
    "A pre-trained model is a saved network that was previously trained on a large dataset, typically on a large-scale image-classification task. Generally, we have two ways to customize a pre-trained model:\n",
    "\n",
    "1. **Feature Extraction**: Use the representations learned by a previous network to extract meaningful features from new samples. You simply add a new classifier, which will be trained from scratch, on top of the pretrained model so that you can repurpose the feature maps learned previously for our dataset. However, the final, classification part of the pretrained model is specific to original classification task, and subsequently specific to the set of classes on which the model was trained. That means you do not need to (re)train the entire model. You \"freeze\" the base convolution network, and only train the newly added classifier layers. \n",
    "\n",
    "2. **Fine-Tuning**: Unfreezing a few of the top layers of a frozen model base and jointly training both the newly-added classifier layers and the last layers of the base model. This allows us to \"fine tune\" the higher-order feature representations in the base model in order to make them more relevant for the specific task.\n",
    "\n",
    "This example uses the base model from __MobileNet__ for a transfer learning of a 10-class classification task on CIFAR-10 dataset. The whole pipeline will include:\n",
    "\n",
    "1. Load data\n",
    "2. Build an input pipeline, in this case using Keras ImageDataGenerator\n",
    "3. Compose our model\n",
    "4. Load in our pretrained base model (and pretrained weights)\n",
    "5. Stack our classification layers on top\n",
    "6. Train our model\n",
    "7. Evaluate model\n",
    "\n",
    "Other references: https://towardsdatascience.com/keras-transfer-learning-for-beginners-6c9b8b7143e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw CIFAR-10 data.\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Data organizations:\n",
    "# Train data: 40000 samples from original train set: 1~40000\n",
    "# Validation data: 1000 samples from original train set: 40001~50000\n",
    "num_training = 40000\n",
    "num_validation = 10000\n",
    "\n",
    "X_val = X_train[-num_validation:, :]\n",
    "y_val = y_train[-num_validation:]\n",
    "\n",
    "X_train = X_train[:num_training, :]\n",
    "y_train = y_train[:num_training]\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "\n",
    "y_train_dummy = tf.keras.utils.to_categorical(y_train)\n",
    "y_val_dummy = tf.keras.utils.to_categorical(y_val)\n",
    "print('Train labels shape (one-hot): ', y_train_dummy.shape)\n",
    "print('Validation labels shape (one-hot): ', y_val_dummy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    'airplanes', 'cars', 'birds', 'cats', 'deer',\n",
    "    'dogs', 'frogs', 'horses', 'ships', 'trucks'\n",
    "]\n",
    "plot(X_val, y_val, names, (32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x) # add dense layers so that the model can learn more complex functions\n",
    "preds = Dense(10, activation='softmax')(x) #final layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    inputs=base_model.input, # specify the inputs\n",
    "    outputs=preds            # specify the outputs\n",
    ")\n",
    "# now a model has been created based on our architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the first 20 layers\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable = False\n",
    "# unfreeze the layers after 20\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Adam optimizer\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 100 #batch size\n",
    "epc = 10 #number of epoches\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
    "train_generator = train_datagen.flow(X_train, y_train_dummy, batch_size=bs)\n",
    "train_step_size = train_generator.n // train_generator.batch_size\n",
    "\n",
    "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
    "valid_generator = valid_datagen.flow(X_val, y_val_dummy, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "history = model.fit(\n",
    "    x=train_generator,\n",
    "    steps_per_epoch=step_size_train,\n",
    "    epochs=epc,\n",
    "    validation_data=valid_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Baseline accuracy: {model.evaluate(valid_generator)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Time Augmentation (TTA)\n",
    "\n",
    "Key references: \n",
    "\n",
    "https://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d\n",
    "\n",
    "https://machinelearningmastery.com/how-to-use-test-time-augmentation-to-improve-model-performance-for-image-classification/\n",
    "\n",
    "\n",
    "Data Augmentation is the process of randomly applying some operations (rotation, zoom, shift, flips, …) to the input data. By this mean, the model can learn more general features about the classes it has to recognize.\n",
    "\n",
    "However, there also exists some ways to improve the results of the model by changing the way we test it. That is Test Time Augmentation (TTA).\n",
    "\n",
    "TTA is now a commonly used technique in Kaggle competition on classification. Similar to what data augmentation is doing to the training set, TTA is to perform similar data modifications to the test images. Thus, instead of showing the regular, “clean” images, only once to the trained model, we will show it the augmented images several times. The final guess of each corresponding image will base on the average of the prediction results.\n",
    "\n",
    "The reason why we refer to TTA is that, by averaging our predictions, on randomly modified images, we are also averaging the errors. The error can be big in a single vector, leading to a wrong answer, but when averaged, only the correct answer stands out. TTA is particularly useful for test images that the model is pretty unsure. The following example will show you how to apply TTA with Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call an ImageDataGenerator similar to training set for test set.\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10.,\n",
    "    fill_mode='reflect', \n",
    "    width_shift_range = 0.1, \n",
    "    height_shift_range = 0.1\n",
    ") #included in our dependencies\n",
    "test_generator = test_datagen.flow(X_val, y_val_dummy, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# test time augmentation, we set TTA for 10 times averaging.\n",
    "tta_steps = 10\n",
    "predictions = []\n",
    "\n",
    "for i in tqdm(range(tta_steps)):\n",
    "    preds = model.predict(test_datagen.flow(X_val, batch_size=bs, shuffle=False), steps=len(X_val)/bs)\n",
    "    predictions.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print final prediction results\n",
    "final_pred = np.mean(predictions, axis=0)\n",
    "print(f'Accuracy with TTA: {np.mean(np.equal(np.argmax(y_val_dummy, axis=-1), np.argmax(final_pred, axis=-1)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
