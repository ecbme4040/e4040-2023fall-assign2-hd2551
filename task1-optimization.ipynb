{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5a8lAWOfmmy"
   },
   "source": [
    "## Columbia University\n",
    "### ECBM E4040 Neural Networks and Deep Learning. Fall 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_bepwPRfmnM"
   },
   "source": [
    "## Assignment 2 - Task 1: Optimization\n",
    "\n",
    "In this task, we introduce several improved optimization algorithms based on stochastic gradient descent (SGD). Naive SGD is a reasonable method to update neural network parameters. However, there exists two main drawbacks:\n",
    "\n",
    "- First, to make SGD perform well, one would need to find an appropriate learning rate and good initial values for the prameters. The training will progress slowly if the learning rate is small, or diverge if the learning rate is too large. Since we often have no prior knowledge about the training data in reality, it is not trivial to find a good learning rate by hand. Also, when the network grows deeper, one may need to set a different learning rate for each layer. \n",
    "\n",
    "- Second, SGD strictly follows the gradients of the **batched data** when updating the parameters. This can be problematic with real-world problems as has been demonstrated in the lectures.\n",
    "\n",
    "To seek for improvements of naive SGD, momentum, parameter estimation and adaptive learning rate methods are commonly the ones to rely on. Here, you are going to experiment with **SGD with Momentum**, **SGD with Nesterov-accelorated Momentum**, **Adam**, **SGD with Backtracing Line Search** and compare their performances.\n",
    "\n",
    "Consult the slides and [text book](https://www.deeplearningbook.org) for details. Here is also [a useful link](http://ruder.io/optimizing-gradient-descent/) to learn more about some methods used in this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kwQ5NoOfmnP"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Import modules\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Da7zcFQffmnd"
   },
   "source": [
    "## Load Fashion-MNIST\n",
    "\n",
    "Here we use a small dataset with only 2500 samples to simulate the \"lack-of-data\" situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1698,
     "status": "ok",
     "timestamp": 1631138412954,
     "user": {
      "displayName": "Sung Jun Won",
      "photoUrl": "",
      "userId": "15792990474350106348"
     },
     "user_tz": 240
    },
    "id": "PpxLY-MWfmne",
    "outputId": "dc0a48ce-34f5-41bb-be66-23a1fb1389bc"
   },
   "outputs": [],
   "source": [
    "# Load the raw Fashion-MNIST data.\n",
    "train, val = fashion_mnist.load_data()\n",
    "\n",
    "X_train_raw, y_train = train\n",
    "X_val_raw, y_val = val\n",
    "\n",
    "X_train = X_train_raw.reshape((X_train_raw.shape[0], X_train_raw.shape[1]**2))\n",
    "X_val = X_val_raw.reshape((X_val_raw.shape[0], X_val_raw.shape[1]**2))\n",
    "\n",
    "#Consider a subset of 2500 samples of the 60000 total images (indexed 10000 ~ 12500)\n",
    "X_val = X_train[10000:10500,:]\n",
    "y_val = y_train[10000:10500]\n",
    "X_train = X_train[10500:12500,:]\n",
    "y_train = y_train[10500:12500]\n",
    "\n",
    "mean_image = np.mean(X_train, axis=0).astype(np.float32)\n",
    "X_train = X_train.astype(np.float32) - mean_image\n",
    "X_val = X_val.astype(np.float32) - mean_image\n",
    "\n",
    "# We have vectorized the data for you\n",
    "# Flatten the 32×32×3 images into 1×3072 Numpy arrays\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20tnMCjyfmnh"
   },
   "source": [
    "## Part 1: Implement Several Optimizers (16%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructors provide code snippets for testing student code implementations.\n",
    "\n",
    "The best anticipated achievable accuracies are specific to each algorithm. You may judge from the the accuracies to check your implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loz33g8Ufmnk"
   },
   "outputs": [],
   "source": [
    "from utils.neuralnets.mlp import MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics\n",
    "\n",
    "Assume that the goal is to optimize an objective function $L$ parametrized by network weights $\\theta \\in R^d$, the update rule of an iterative optimization algorithm in general can be formulated as\n",
    "\n",
    "$$\\theta_{t+1} \\gets \\theta_t + \\alpha_t p_t$$\n",
    "\n",
    "where $\\alpha_t > 0$ is the **step size** and $p$ is the **direction of update**. \n",
    "\n",
    "Both $\\alpha$ and $p$ can be proposed in numerous different ways which result in different optimizers with different performances.\n",
    "\n",
    "Note that in the following equations, we ***DO NOT*** take learning rate decay into consideration. This has been implemented in the base class `Optimizer.train()`. All optimizers will be derived from this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_4iVMT2fmnm"
   },
   "source": [
    "### Original SGD (For Comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At time step $t$, let the gradient of a real-valued loss function $L$ w.r.t network parameter $\\theta$ be given by\n",
    "\n",
    "$$g_t = \\nabla_{\\theta_t} L(\\theta_t)$$\n",
    "\n",
    "and $\\theta_t$ denotes the values of the parameters at time $t$.\n",
    "\n",
    "As you have seen in previous examples, the loss $L$ is calculated from a mini-batch stochastically sampled from the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD (Stochastic Gradient Descent) algorithm is formulated as\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta g_t$$\n",
    "\n",
    "where $\\eta$ is the ***learning rate***. \n",
    "\n",
    "The final accuracy you should expect is arround 0.1-0.3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4609,
     "status": "ok",
     "timestamp": 1631138989515,
     "user": {
      "displayName": "Sung Jun Won",
      "photoUrl": "",
      "userId": "15792990474350106348"
     },
     "user_tz": 240
    },
    "id": "crxdrUTvfmnn",
    "outputId": "8c1cb517-e687-407d-bcf3-300b29383430"
   },
   "outputs": [],
   "source": [
    "from utils.optimizers import SGDOptim\n",
    "\n",
    "model = MLP(\n",
    "    input_dim=X_train.shape[1], hidden_dims=[100, 100],\n",
    "    num_classes=10, weight_scale=1e-3, l2_reg=0.0\n",
    ")\n",
    "optimizer = SGDOptim(model)\n",
    "hist_sgd = optimizer.train(\n",
    "    X_train, y_train, X_val, y_val, \n",
    "    num_epoch=15, batch_size=200, learning_rate=1e-2, learning_decay=0.95, \n",
    "    verbose=False, record_interval=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Find A Better Direction\n",
    "\n",
    "As naively in SGD, the step size $\\alpha_t = \\eta$ is fixed to be the learning rate and the update direction $p_t = -g_t$ is simply the opposite of the gradient. Now let's look at some algorithms that try to use a different $p$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZauLVUBlfmno"
   },
   "source": [
    "#### SGD + Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All gradient methods share the disadvantage of being stuck by local minima. Momentum is one possible way out. By accumulating previous \"velocities\" of update, the algorithm can potentially jump out of a local minima and give faster convergence.\n",
    "\n",
    "The algorithm is formulated as two steps:\n",
    "1. Accumulate the **velocities**:\n",
    "   $$v_t = \\beta v_{t-1} + g_t$$\n",
    "2. Update the parameters:\n",
    "   $$\\theta_{t+1} = \\theta_t - \\eta v_t$$\n",
    "\n",
    "where $\\beta \\in [0, 1]$ is the decay factor controlling the effect of past velocities on the current update and $v_0$ is initialized to be $\\mathbb{0}$.\n",
    "\n",
    "The intuition is to modify the current update direction (naively $g_t$ in SGD) by accumulated past directions. You can think of it as rolling a heavy ball down the hill, where the inertia of the ball will always try to retain the direction of the current velocity instead of simply following the slope.\n",
    "\n",
    "The final accuracy you should expect is arround 0.5-0.7. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO:__</span> Implement SGD + Momentum by editing `SGDmomentumOptim` in **./utils/optimizers.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5250,
     "status": "ok",
     "timestamp": 1631139111767,
     "user": {
      "displayName": "Sung Jun Won",
      "photoUrl": "",
      "userId": "15792990474350106348"
     },
     "user_tz": 240
    },
    "id": "oFTM2qtafmno",
    "outputId": "03fbd2a0-336b-4177-98dc-38cb6c5a3027"
   },
   "outputs": [],
   "source": [
    "# Verification code for your implemention\n",
    "# Please don't change anything.\n",
    "\n",
    "from utils.optimizers import SGDMomentumOptim\n",
    "\n",
    "model = MLP(\n",
    "    input_dim=X_train.shape[1], hidden_dims=[100, 100],\n",
    "    num_classes=10, weight_scale=1e-3, l2_reg=0.0\n",
    ")\n",
    "optimizer = SGDMomentumOptim(model, momentum=0.8)\n",
    "hist_sgd_momentum = optimizer.train(\n",
    "    X_train, y_train, X_val, y_val, \n",
    "    num_epoch=15, batch_size=200, learning_rate=1e-2, \n",
    "    learning_decay=0.95, verbose=False, record_interval=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD + Nesterov-accelorated Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While momentum shows exciting results for an algorithm as simple as above, the convergence rate can be further improved by introducing the Nesterov acceloration.\n",
    "\n",
    "As an intuition, the previous algorithm only modify the parameters using the momentum at the **current** time step $v_t$. Nesterov proposed to derive an estimation of the momentum at the **next** time step $\\hat v_{t+1}$ to perform the update.\n",
    "\n",
    "This translates to the following algorithm:\n",
    "1. Accumulate the velocities:\n",
    "   $$v_t = \\beta v_{t-1} + g_t$$\n",
    "2. **Nesterov acceloration**:\n",
    "   $$\\hat v_{t+1} = \\beta v_t + g_t$$\n",
    "3. Update the parameters:\n",
    "   $$\\theta_{t+1} = \\theta_t - \\eta \\hat v_{t+1}$$\n",
    "\n",
    "The final accuracy you should expect is arround 0.7-0.9. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO:__</span> Implement SGD + Momentum by editing `SGDmomentumOptim` in **./utils/optimizers.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification code for your implemention\n",
    "# Please don't change anything.\n",
    "\n",
    "from utils.optimizers import SGDNestMomentumOptim\n",
    "\n",
    "model = MLP(\n",
    "    input_dim=X_train.shape[1], hidden_dims=[100, 100],\n",
    "    num_classes=10, weight_scale=1e-3, l2_reg=0.0\n",
    ")\n",
    "optimizer = SGDNestMomentumOptim(model, momentum=0.9)\n",
    "hist_sgd_nesterov = optimizer.train(\n",
    "    X_train, y_train, X_val, y_val, \n",
    "    num_epoch=15, batch_size=200, learning_rate=1e-2, \n",
    "    learning_decay=0.95, verbose=False, record_interval=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5ZEf-udfmnv"
   },
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the algorithm above, we're already implying the notion of **[moment](https://en.wikipedia.org/wiki/Moment_(mathematics)) estimation** (i.e. $\\hat v_{t+1}$) in the sense of Nesterov by combining current gradient and exponetially decaying past gradients (with factor $\\beta$). Here we explore another more flexible and widely used estimation method - the **moving average**.\n",
    "\n",
    "For any time series denoted by $x_0, x_1, \\dots, x_t$, its moving average at time $t$ is defined iteratively as a weighted summation of the previous average and current value, i.e.\n",
    "\n",
    "$$\\mu_t = \\beta \\mu_{t-1} + (1 - \\beta) x_t$$\n",
    "\n",
    "where the hyperparameter $\\beta \\in [0, 1]$ is the decay factor controlling the influence of the past to the present. This provides the algorithm with better adaptations to the change of parameters through time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, we would want to know *statistically* how far our moving average $\\mu_t$ deviates from the true average $\\mu$ by considering its expectation $\\mathbb{E}[\\mu_t]$.\n",
    "\n",
    "Specifically, the moving average can be expanded (by plugging in each $\\mu_t$) to\n",
    "\n",
    "$$\\mu_t = (1 - \\beta) \\sum_{i=1}^t \\beta^{t-i} x_i$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\mu_t]\n",
    "= \\mathbb{E} \\left[ (1 - \\beta) \\sum_{i=1}^t \\beta^{t-i} x_i \\right]\n",
    "= (1 - \\beta) \\sum_{i=1}^t \\beta^{t-i} \\mathbb{E}[x_i]\n",
    "$$\n",
    "\n",
    "Assume that the series elements are identically distributed (i.e. $\\mathbb{E}[x_1] = \\dots = \\mathbb{E}[x_t] = \\mu$), then\n",
    "\n",
    "$$\\mathbb{E}[\\mu_t] = \\mu (1 - \\beta) \\sum_{i=1}^t \\beta^{t-i} = (1 - \\beta^t) \\mu$$\n",
    "\n",
    "Therefore, a bias-corrected moving average can be given by\n",
    "\n",
    "$$\\hat \\mu_t = \\frac{\\mu_t}{1 - \\beta^t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the discussions above, Adam (Adaptive Moment Estimation) algorithm can be formulated into three following steps.\n",
    "\n",
    "**1. Moment calculation**\n",
    "   - The 1st moment (**mean**) of the gradients:\n",
    "     $$m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t$$\n",
    "   - The 2nd moment (**variance**) of the gradients:\n",
    "     $$v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Bias correction**\n",
    "\n",
    "   - Adjust the 1st moment:\n",
    "   $$\\hat m_t = \\frac{m_t}{1 - \\beta_1^t}$$\n",
    "   - Adjust the 2nd moment:\n",
    "   $$\\hat v_t = \\frac{v_t}{1 - \\beta_2^t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Parameter update**\n",
    "\n",
    "   $$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat v_t}+\\epsilon} \\odot \\hat m_t$$\n",
    "\n",
    "   Here, $\\epsilon$ is a small value (e.g. 1e-8) serves to avoid zero-division and $\\odot$ denotes the Hadamard (element-wise) product.\n",
    "\n",
    "The final accuracy you should expect is arround 0.8-0.9. \n",
    "\n",
    "**This is usually (not always) the optimal choice in practice.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO:__</span> Implement Adam by editing `AdamOptim` in **./utils/optimizers.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5220,
     "status": "ok",
     "timestamp": 1631139271319,
     "user": {
      "displayName": "Sung Jun Won",
      "photoUrl": "",
      "userId": "15792990474350106348"
     },
     "user_tz": 240
    },
    "id": "aTws4phjfmnw",
    "outputId": "90f0732d-6062-4b8e-ffaf-6978d05958bf"
   },
   "outputs": [],
   "source": [
    "# Verification code for your implemention\n",
    "# Please don't change anything.\n",
    "\n",
    "from utils.optimizers import AdamOptim\n",
    "\n",
    "model = MLP(\n",
    "    input_dim=X_train.shape[1], hidden_dims=[100, 100],\n",
    "    num_classes=10, weight_scale=1e-3, l2_reg=0.0\n",
    ")\n",
    "optimizer = AdamOptim(model, beta1=0.9, beta2=0.99)\n",
    "hist_adam = optimizer.train(\n",
    "    X_train, y_train, X_val, y_val, \n",
    "    num_epoch=15, batch_size=200, learning_rate=1e-3, \n",
    "    learning_decay=0.95, verbose=False, record_interval=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Find A Better Step Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the general parameter update rule:\n",
    "\n",
    "$$\\theta_{t+1} \\gets \\theta_t + \\alpha_t p_t$$\n",
    "\n",
    "On the basis of naive SGD where $p_t = -g_t$, we have already come across three other algorithms that seeks different $p_t$:\n",
    "- SGD + Momentum: $p_t = - \\beta v_t$ is the velocity\n",
    "- SGD + Nesterov Momentum: $p_t = - \\beta \\hat v_t$ is the Nesterov accelorated momentum\n",
    "- Adam: $p_t =  - \\hat m_t$ is the (bias-corrected) estimated 1st moment\n",
    "\n",
    "While the former two assume fixed $\\alpha_t = \\eta$, Adam can also be intrepreted as attenuating the step size w.r.t. each individual parameter using their estimated variances $\\hat v_t$.\n",
    "\n",
    "Now let's look at another algorithm that tries to select different $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backtracing Line Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition, gradient provides **local** information about an objective function. If one moves the parameters in the opposite direction to the gradient, the value of the loss will **always** decrease as long as the step size is sufficiently small.\n",
    "\n",
    "However, a minimal step size will not be useful in practice due to slow convergence. It is thus an interesting problem of how an appropriate step size can be chosen. One of the solutions is [**line search**](https://optimization.cbe.cornell.edu/index.php?title=Line_search_methods).\n",
    "\n",
    "![](utils/notebook_images/task2_1_search.png)\n",
    "\n",
    "In this graph, $\\alpha$ is the step size and the value of the loss $\\phi$ (this corresponds to our $L$) is plotted as a function of different $\\alpha$ for updating the parameters $x_k$ (this corresponds to our $\\theta_t$).\n",
    "\n",
    "Back to our notations, different choices of step size $\\alpha_t$ may result in dramatically different destination of $\\theta_{t+1}$ for a fixed update direction $p_t$. All of these posible destinations lie in a linear subspace of $\\theta$ parametrized by $\\alpha_t$, which gives name to this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backtracing is a straightforward line search algorithm that starts with a fairly large initial step size, and then repeatedly ***tries*** a smaller step until an appropriate loss value is met.\n",
    "\n",
    "The algorithm can be combined with a naive SGD and reads as follows.\n",
    "> 1. Compute the current loss: $L (\\theta_t)$ <br>\n",
    "> 2. Set SGD update direction: $p_t \\gets g_t$ <br>\n",
    "> 3. Set the initial step size: $\\alpha_t \\gets \\eta$ <br>\n",
    "> 4. $n \\gets 0$ <br>\n",
    "> 5. While $n < N$, do: <br>\n",
    ">    (a) Shrink the step size: $\\alpha_t \\gets \\beta \\alpha_t$ <br>\n",
    ">    (b) Compute the **Armijo upper bound**: $U_t \\gets L_t (\\theta_t) - C \\alpha_t p_t^T g_t$ <br>\n",
    ">    (c) Update model parameter: $\\theta_{t+1} \\gets \\theta_t - \\alpha_t p_t$ <br>\n",
    ">    (d) Compute the updated loss: $L (\\theta_{t+1})$ <br>\n",
    ">    (e) $n \\gets n + 1$ <br>\n",
    ">    If $L (\\theta_{t+1}) < U_t$, then break <br>\n",
    "> 6. Return\n",
    "\n",
    "Here, $\\eta$ is a large initial step size (learning rate) and $N$ is the maximum number of searching iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a closer look at the stopping criterion $p_t$.\n",
    "\n",
    "$$L(\\theta_{t+1}) < L(\\theta_t) - C \\alpha p_t^T g_t$$\n",
    "\n",
    "Particularly, LHS is the value of the loss **after** the update, and $p_t^T g_t$ is the **scalar product** (dot-product of the flattened vectors) which is always positive. Thus the RHS describes a linear upper bound of LHS parametrized by $\\alpha$, illustrated as the dotted line in the graph above.\n",
    "\n",
    "This criterion is called the **Armijo (sufficient decrease)** condition, stating that after updating the parameters, the value of the loss **must** fall below this upperbound to guarantee a sufficient decrease. The hyperparameter $C$ controls the **slope** of the linear upper bound. A larger $C$ imposes harder constraints on LHS value.\n",
    "\n",
    "The accuracy you should expect is arround 0.5-0.7. Note that this is **NOT** a commonly used method in DL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO:__</span> Implement SGD + Backtrace by editing `BacktraceSGDOptim` in **./utils/optimizers.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification code for your implemention\n",
    "# Please don't change anything.\n",
    "\n",
    "from utils.optimizers import BacktraceSGDOptim\n",
    "\n",
    "model = MLP(\n",
    "    input_dim=X_train.shape[1], hidden_dims=[100, 100],\n",
    "    num_classes=10, weight_scale=1e-3, l2_reg=0.0\n",
    ")\n",
    "optimizer = BacktraceSGDOptim(model, c=10, beta=0.5, max_searches=20)\n",
    "hist_backtrace = optimizer.train(\n",
    "    X_train, y_train, X_val, y_val, \n",
    "    num_epoch=15, batch_size=200, learning_rate=1e-2, \n",
    "    learning_decay=1, verbose=False, record_interval=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dga2dgGxfmny"
   },
   "source": [
    "## Part 2: Comparison (4%)\n",
    "\n",
    "<span style=\"color:red\">__TODO:__</span> Run the following cells, which plot the loss, training accuracy, and validation accuracy curves of different optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mzui75QUfmny"
   },
   "outputs": [],
   "source": [
    "loss_hist_sgd, train_acc_hist_sgd, val_acc_hist_sgd = hist_sgd\n",
    "loss_hist_momentum, train_acc_hist_momentum, val_acc_hist_momentum = hist_sgd_momentum\n",
    "loss_hist_nesterov, train_acc_hist_nesterov, val_acc_hist_nesterov = hist_sgd_nesterov\n",
    "loss_hist_adam, train_acc_hist_adam, val_acc_hist_adam = hist_adam\n",
    "loss_hist_backtrace, train_acc_hist_backtrace, val_acc_hist_backtrace = hist_backtrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1631139318716,
     "user": {
      "displayName": "Sung Jun Won",
      "photoUrl": "",
      "userId": "15792990474350106348"
     },
     "user_tz": 240
    },
    "id": "oX9CyZjLfmnz",
    "outputId": "ce4a99cd-8663-4a2c-cdca-6ab7b95125c9"
   },
   "outputs": [],
   "source": [
    "# Plot the training error curves for implemented optimizers\n",
    "plt.plot(loss_hist_sgd, label=\"sgd\")\n",
    "plt.plot(loss_hist_momentum, label=\"momentum\")\n",
    "plt.plot(loss_hist_nesterov, label=\"nesterov\")\n",
    "plt.plot(loss_hist_adam, label=\"adam\")\n",
    "plt.plot(loss_hist_backtrace, label=\"backtrace\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1631139328348,
     "user": {
      "displayName": "Sung Jun Won",
      "photoUrl": "",
      "userId": "15792990474350106348"
     },
     "user_tz": 240
    },
    "id": "JVigWVU1fmn0",
    "outputId": "c836fcfb-5350-4fbc-ccee-32270aa834e8"
   },
   "outputs": [],
   "source": [
    "# Plot the training accuracy curves for implemented optimizers\n",
    "plt.plot(train_acc_hist_sgd, label=\"sgd\")\n",
    "plt.plot(train_acc_hist_momentum, label=\"momentum\")\n",
    "plt.plot(train_acc_hist_nesterov, label=\"nesterov\")\n",
    "plt.plot(train_acc_hist_adam, label=\"adam\")\n",
    "plt.plot(train_acc_hist_backtrace, label=\"backtrace\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1631139339586,
     "user": {
      "displayName": "Sung Jun Won",
      "photoUrl": "",
      "userId": "15792990474350106348"
     },
     "user_tz": 240
    },
    "id": "7AIf6zjpfmn1",
    "outputId": "25c10de5-13a4-40f9-e721-68f2d9ceb852"
   },
   "outputs": [],
   "source": [
    "# Plot the validation accuracy curves for implemented optimizers\n",
    "plt.plot(val_acc_hist_sgd, label=\"sgd\")\n",
    "plt.plot(val_acc_hist_momentum, label=\"momentum\")\n",
    "plt.plot(val_acc_hist_nesterov, label=\"nesterov\")\n",
    "plt.plot(val_acc_hist_adam, label=\"adam\")\n",
    "plt.plot(val_acc_hist_backtrace, label=\"backtrace\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4aY4q4wfmn2"
   },
   "source": [
    "<span style=\"color:red\">**TODO:**</span> Compare the results from above. Answer the following questions based on your observations and understandings of these optimizers:\n",
    "\n",
    "1. Briefly conclude why each of the optimizers beats naive SGD. Which of them is the winner based on your results?\n",
    "2. How does backtracing improves the naive SGD? What is the main drawback of line search that prevents its application in the optmization of deep neural networks?\n",
    "3. Briefly describe another optimizer that is not introduced in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uL5H31uzfmn3"
   },
   "source": [
    "Answer: **[fill in herer]**."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task1-optimization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "36142657f443a869bd2c1b509e6f1df9b014ad48aa206cdd00d27f8f22cb37ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
